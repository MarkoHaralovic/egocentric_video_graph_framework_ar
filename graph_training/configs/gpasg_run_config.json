{
  "experiment_name": "gaze_pruned_graph_mlp_baseline",
  "mlp" : {
    "fc_layers_num": 2,
    "num_graphs" : 10,
    "use_pool" : true,
    "use_proj" : true,
    "action_graph_embedder" : {
      "clip_text_emb_out_feats" : 64,
      "emb_dim" : 32,
      "obj_out" : 32,
      "aux_out" : 0,
      "attr_out" : 32,
      "rel_out" : 32,
      "trip_out" :  32,
      "k_obj" :  2,
      "k_aux" : 0,
      "k_trip" :  2,
      "clip_dim" : 1280,
      "clip_emb_dim" : 640,
      "obj_feat_dim" : 256,
      "use_triplets" : true,  
      "use_clip_text_emb" : false
    },
    "projector" : {
      "graph_emb_dim" : 256,
      "layer_norm" : true,
      "gelu" : true
    },
    "attention_pooler" : {
      "graph_pool_interim_feat" : 128,
      "final_graph_emb_dim" : 64
    }
  },
  "data": {
    "input_path" : "/home/s3758869/vlm_datasets/AriaEA_vlm_ann_3_10_llava-v1.6-34b-hf",
    "batch_size": 1,
    "num_workers": 16,
    "pin_memory": true,
    "graph_type" : "pruned" 
  },
  "training": {
    "num_epochs": 20,
    "optimizer": "adam",
    "learning_rate": 0.0005,
    "weight_decay": 1e-05,
    "scheduler_factor": 1.0,
    "criterion_metrics": ["f1", "acc"],
    "loss": {
      "name": "cross_entropy",
      "ifw": false,
      "focal_gamma": 2.0
    }
  },
  "output": {
    "base_path": "/home/s3758869/egocentric_video_graph_framework_ar/outputs/graph_mlp_baseline"
  },
  "device": "cpu"
}
